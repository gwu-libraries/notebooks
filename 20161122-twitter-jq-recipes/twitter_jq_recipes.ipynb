{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recipes for processing Twitter data with jq\n",
    "This notebook is a companion to [Getting Started Working with Twitter Data Using jq](http://nbviewer.jupyter.org/github/gwu-libraries/notebooks/blob/master/20160407-twitter-analysis-with-jq/Working-with-twitter-using-jq.ipynb). It focuses on recipes that the [Social Feed Manager](http://gwu-libraries.github.io/sfm-ui/) team has used when preparing datasets of tweets for researchers.\n",
    "\n",
    "We will continue to add additional recipes to this notebook. If you have any suggestions, please [contact us](http://gwu-libraries.github.io/sfm-ui/contact).\n",
    "\n",
    "This notebook requires at least [jq](https://stedolan.github.io/jq/) 1.5. Note that only earlier versions may be available from your package manager; manual installation may be necessary.\n",
    "\n",
    "These recipes can be used with any data source that outputs tweets as line-oriented JSON. Within the context of SFM, this is usually the output of [twitter_rest_warc_iter.py or twitter_stream_warc_iter.py](http://sfm.readthedocs.io/en/latest/processing.html#warc-iterators) within a [processing container](http://sfm.readthedocs.io/en/latest/processing.html#processing-in-container). Alternatively, [Twarc](https://github.com/DocNow/twarc) is a commandline tool for retrieving data from the Twitter API that outputs tweets as line-oriented JSON.\n",
    "\n",
    "For the purposes of this notebook, we will use a line-oriented JSON file that was created using Twarc. It contains the user timeline of @SocialFeedMgr. The command used to produce this file was `twarc.py --timeline socialfeedmgr > tweets.json`.\n",
    "\n",
    "For an explanation of the fields in a tweet see the [Tweet Field Guide](https://dev.twitter.com/overview/api/tweets). For other helpful tweet processing utilities, see [twarc utils](https://github.com/DocNow/twarc/tree/master/utils).\n",
    "\n",
    "For the sake of brevity, some of the examples may only output a subset of the tweets fields and/or a subset of the tweets contained in `tweets.json`. The following example outputs the tweet id and text of all of the first 5 tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\u001b[0;39m798895564335280100\u001b[0m\u001b[1;39m,\u001b[0;32m\"Social Feed Manager 1.3 is out, with collection portability, monitoring page, one-time harvest option, more https://t.co/L956zwfrGQ\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m797074713612877800\u001b[0m\u001b[1;39m,\u001b[0;32m\"@SMLabTO How might we update the toolkit's listing for Social Feed Manager? Info and docs available via https://t.co/j3zQ7kGwNn\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m797064988116611100\u001b[0m\u001b[1;39m,\u001b[0;32m\"RT @justin_littman: New on the @SocialFeedMgr blog: On retweets, replies, quotes &amp; favorites: A guide for researchers. https://t.co/SjfIuLu…\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m794234002496487400\u001b[0m\u001b[1;39m,\u001b[0;32m\"RT @ianmilligan1: Used @SocialFeedMgr to collect almost 80,000 #CdnPoli tweets this morning. Great, intuitive UI. https://t.co/BuS3S7f6kf #…\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m793896478037114900\u001b[0m\u001b[1;39m,\u001b[0;32m\"Software doesn't live forever. How to get collections OUT of Social Feed Manager, a new blog post by @justin_littman https://t.co/CagQvSF7pJ\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!head -n5 tweets.json | jq -c '[.id, .text]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates\n",
    "For both filtering and output, it is often necessary to parse and/or normalize the `created_at` date. The following shows the original `created_at` date and the date as an ISO 8601 date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\u001b[0;32m\"2016-11-16T09:28:39Z\"\u001b[0m\u001b[1;39m,\u001b[0;32m\"2016-11-16T09:28:39Z\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;32m\"2016-11-11T08:53:15Z\"\u001b[0m\u001b[1;39m,\u001b[0;32m\"2016-11-11T08:53:15Z\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;32m\"2016-11-11T08:14:36Z\"\u001b[0m\u001b[1;39m,\u001b[0;32m\"2016-11-11T08:14:36Z\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;32m\"2016-11-03T13:45:17Z\"\u001b[0m\u001b[1;39m,\u001b[0;32m\"2016-11-03T13:45:17Z\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;32m\"2016-11-02T15:24:04Z\"\u001b[0m\u001b[1;39m,\u001b[0;32m\"2016-11-02T15:24:04Z\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!head -n5 tweets.json | jq -c '[.created_at, .created_at | strptime(\"%A %B %d %T %z %Y\") | todate]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering text\n",
    "#### Case sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\u001b[0;39m797064988116611100\u001b[0m\u001b[1;39m,\u001b[0;32m\"RT @justin_littman: New on the @SocialFeedMgr blog: On retweets, replies, quotes &amp; favorites: A guide for researchers. https://t.co/SjfIuLu…\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m793896478037114900\u001b[0m\u001b[1;39m,\u001b[0;32m\"Software doesn't live forever. How to get collections OUT of Social Feed Manager, a new blog post by @justin_littman https://t.co/CagQvSF7pJ\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m786179196577992700\u001b[0m\u001b[1;39m,\u001b[0;32m\"A detailed look at recent technical work to improve our social media harvesters. New blog post by @justinlittman: https://t.co/FFHqJxfxl6\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m773553804558073900\u001b[0m\u001b[1;39m,\u001b[0;32m\"When is a Collection not an Archive? New blog post by @save4use https://t.co/JtxyksXLdV\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m742420371434033200\u001b[0m\u001b[1;39m,\u001b[0;32m\"RT @justin_littman: My blog post on collecting the tweets of #PulseNightclub with @SocialFeedMgr: https://t.co/qRQRNPRiOO\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m728300814129827800\u001b[0m\u001b[1;39m,\u001b[0;32m\"Another Try at Harvesting the Twitter Streaming API to WARC files, blog post by @justin_littman https://t.co/RJL9OqaGDW\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m720616794168369200\u001b[0m\u001b[1;39m,\u001b[0;32m\"More on Social Feed Manager and blog posts about the WARC approach at https://t.co/iUdSktNyRp https://t.co/XKIiqaKDDp\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!cat tweets.json | jq -c 'select(.text | contains(\"blog\")) | [.id, .text]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!cat tweets.json | jq -c 'select(.text | contains(\"BLOG\")) | [.id, .text]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case insensitive\n",
    "To ignore case, use a [regular expression filter](https://stedolan.github.io/jq/manual/#RegularexpressionsPCRE) with the case-insensitive flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\u001b[0;39m797064988116611100\u001b[0m\u001b[1;39m,\u001b[0;32m\"RT @justin_littman: New on the @SocialFeedMgr blog: On retweets, replies, quotes &amp; favorites: A guide for researchers. https://t.co/SjfIuLu…\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m793896478037114900\u001b[0m\u001b[1;39m,\u001b[0;32m\"Software doesn't live forever. How to get collections OUT of Social Feed Manager, a new blog post by @justin_littman https://t.co/CagQvSF7pJ\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m786179196577992700\u001b[0m\u001b[1;39m,\u001b[0;32m\"A detailed look at recent technical work to improve our social media harvesters. New blog post by @justinlittman: https://t.co/FFHqJxfxl6\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m773553804558073900\u001b[0m\u001b[1;39m,\u001b[0;32m\"When is a Collection not an Archive? New blog post by @save4use https://t.co/JtxyksXLdV\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m742420371434033200\u001b[0m\u001b[1;39m,\u001b[0;32m\"RT @justin_littman: My blog post on collecting the tweets of #PulseNightclub with @SocialFeedMgr: https://t.co/qRQRNPRiOO\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m728300814129827800\u001b[0m\u001b[1;39m,\u001b[0;32m\"Another Try at Harvesting the Twitter Streaming API to WARC files, blog post by @justin_littman https://t.co/RJL9OqaGDW\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m720616794168369200\u001b[0m\u001b[1;39m,\u001b[0;32m\"More on Social Feed Manager and blog posts about the WARC approach at https://t.co/iUdSktNyRp https://t.co/XKIiqaKDDp\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!cat tweets.json | jq -c 'select(.text | test(\"BLog\"; \"i\")) | [.id, .text]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering on multiple terms (OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\u001b[0;39m797064988116611100\u001b[0m\u001b[1;39m,\u001b[0;32m\"RT @justin_littman: New on the @SocialFeedMgr blog: On retweets, replies, quotes &amp; favorites: A guide for researchers. https://t.co/SjfIuLu…\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m793896478037114900\u001b[0m\u001b[1;39m,\u001b[0;32m\"Software doesn't live forever. How to get collections OUT of Social Feed Manager, a new blog post by @justin_littman https://t.co/CagQvSF7pJ\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m786179196577992700\u001b[0m\u001b[1;39m,\u001b[0;32m\"A detailed look at recent technical work to improve our social media harvesters. New blog post by @justinlittman: https://t.co/FFHqJxfxl6\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m773553804558073900\u001b[0m\u001b[1;39m,\u001b[0;32m\"When is a Collection not an Archive? New blog post by @save4use https://t.co/JtxyksXLdV\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m742420371434033200\u001b[0m\u001b[1;39m,\u001b[0;32m\"RT @justin_littman: My blog post on collecting the tweets of #PulseNightclub with @SocialFeedMgr: https://t.co/qRQRNPRiOO\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m741072574239649800\u001b[0m\u001b[1;39m,\u001b[0;32m\"Glad to contribute to twarc, for the benefit of everyone needing access to twitter data. https://t.co/gwKXit2cho\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m728300814129827800\u001b[0m\u001b[1;39m,\u001b[0;32m\"Another Try at Harvesting the Twitter Streaming API to WARC files, blog post by @justin_littman https://t.co/RJL9OqaGDW\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m720616794168369200\u001b[0m\u001b[1;39m,\u001b[0;32m\"More on Social Feed Manager and blog posts about the WARC approach at https://t.co/iUdSktNyRp https://t.co/XKIiqaKDDp\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!cat tweets.json | jq -c 'select(.text | test(\"BLog|twarc\"; \"i\")) | [.id, .text]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering on multiple terms (AND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\u001b[0;39m728300814129827800\u001b[0m\u001b[1;39m,\u001b[0;32m\"Another Try at Harvesting the Twitter Streaming API to WARC files, blog post by @justin_littman https://t.co/RJL9OqaGDW\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!cat tweets.json | jq -c 'select((.text | test(\"BLog\"; \"i\")) and (.text | test(\"twitter\"; \"i\"))) | [.id, .text]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter dates\n",
    "The following shows tweets created after November 5, 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\u001b[0;39m798895564335280100\u001b[0m\u001b[1;39m,\u001b[0;32m\"Wed Nov 16 14:28:39 +0000 2016\"\u001b[0m\u001b[1;39m,\u001b[0;32m\"2016-11-16T09:28:39Z\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m797074713612877800\u001b[0m\u001b[1;39m,\u001b[0;32m\"Fri Nov 11 13:53:15 +0000 2016\"\u001b[0m\u001b[1;39m,\u001b[0;32m\"2016-11-11T08:53:15Z\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m797064988116611100\u001b[0m\u001b[1;39m,\u001b[0;32m\"Fri Nov 11 13:14:36 +0000 2016\"\u001b[0m\u001b[1;39m,\u001b[0;32m\"2016-11-11T08:14:36Z\"\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!cat tweets.json | jq -c 'select((.created_at | strptime(\"%A %B %d %T %z %Y\") | mktime) > (\"2016-11-05T00:00:00Z\" | fromdateiso8601)) | [.id, .created_at, (.created_at | strptime(\"%A %B %d %T %z %Y\") | todate)]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is retweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\u001b[0;39m797064988116611100\u001b[0m\u001b[1;39m,\u001b[0;39m796843045341790200\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m794234002496487400\u001b[0m\u001b[1;39m,\u001b[0;39m794224602310463500\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m793786215220777000\u001b[0m\u001b[1;39m,\u001b[0;39m793748406602723300\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m791966708390957000\u001b[0m\u001b[1;39m,\u001b[0;39m791929123723632600\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m791633052053176300\u001b[0m\u001b[1;39m,\u001b[0;39m791632539341447200\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m789442614571466800\u001b[0m\u001b[1;39m,\u001b[0;39m789416330009120800\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m785833961847001100\u001b[0m\u001b[1;39m,\u001b[0;39m785802401512947700\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m780736483682549800\u001b[0m\u001b[1;39m,\u001b[0;39m780732775963983900\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m773231772398194700\u001b[0m\u001b[1;39m,\u001b[0;39m773229286589341700\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m766639464454193200\u001b[0m\u001b[1;39m,\u001b[0;39m765636639133691900\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m758383727672225800\u001b[0m\u001b[1;39m,\u001b[0;39m758316697560416300\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m752856372644024300\u001b[0m\u001b[1;39m,\u001b[0;39m752584251648774100\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m750704374876364800\u001b[0m\u001b[1;39m,\u001b[0;39m750391045301559300\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m743462280852086800\u001b[0m\u001b[1;39m,\u001b[0;39m743459400967413800\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m743458848434958300\u001b[0m\u001b[1;39m,\u001b[0;39m743458460205989900\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m743410385923997700\u001b[0m\u001b[1;39m,\u001b[0;39m743121113035771900\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m743167286006079500\u001b[0m\u001b[1;39m,\u001b[0;39m743166124133650400\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m743128282720284700\u001b[0m\u001b[1;39m,\u001b[0;39m743127197066612700\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m742420371434033200\u001b[0m\u001b[1;39m,\u001b[0;39m742418514686926800\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m742053812895027200\u001b[0m\u001b[1;39m,\u001b[0;39m742048151176151000\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m720621348565971000\u001b[0m\u001b[1;39m,\u001b[0;39m720621197550071800\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m720223544014213100\u001b[0m\u001b[1;39m,\u001b[0;39m720222105435009000\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m715610839890403300\u001b[0m\u001b[1;39m,\u001b[0;39m715607896793477100\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!cat tweets.json | jq -c 'select(has(\"retweeted_status\")) | [.id, .retweeted_status.id]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;39m[\u001b[0;39m789100742430888000\u001b[0m\u001b[1;39m,\u001b[0;39m789098583362502700\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m745995798354210800\u001b[0m\u001b[1;39m,\u001b[0;39m745988440794210300\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m741072574239649800\u001b[0m\u001b[1;39m,\u001b[0;39m741018168773226500\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n",
      "\u001b[1;39m[\u001b[0;39m720616794168369200\u001b[0m\u001b[1;39m,\u001b[0;39m720615458412605400\u001b[0m\u001b[1;39m\u001b[1;39m]\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!cat tweets.json | jq -c 'select(has(\"quoted_status\")) | [.id, .quoted_status.id]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output\n",
    "To write output to a file use `> <filename>`. For example: `cat tweets.json | jq -c '.id' > tweet_ids.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "Following is a CSV output that has fields similar to the CSV output produced by [SFM's export functionality](http://sfm.readthedocs.io/en/latest/quickstart.html#exports).\n",
    "\n",
    "Note that is uses the `-r` flag for jq instead of the `-c` flag.\n",
    "\n",
    "Also note that is it is necessary to remove line breaks from the tweet text to prevent it from breaking the CSV. This is done with `(.text | gsub(\"\\n\";\" \"))`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"2016-11-16T09:28:39Z\",\"798895564335280129\",\"SocialFeedMgr\",124,27,1,0,,\"http://twitter.com/SocialFeedMgr/status/798895564335280129\",\"Social Feed Manager 1.3 is out, with collection portability, monitoring page, one-time harvest option, more https://t.co/L956zwfrGQ\",false,false\r\n",
      "\"2016-11-11T08:53:15Z\",\"797074713612877824\",\"SocialFeedMgr\",124,27,0,0,\"SMLabTO\",\"http://twitter.com/SocialFeedMgr/status/797074713612877824\",\"@SMLabTO How might we update the toolkit's listing for Social Feed Manager? Info and docs available via https://t.co/j3zQ7kGwNn\",false,false\r\n",
      "\"2016-11-11T08:14:36Z\",\"797064988116611073\",\"SocialFeedMgr\",124,27,4,0,,\"http://twitter.com/SocialFeedMgr/status/797064988116611073\",\"RT @justin_littman: New on the @SocialFeedMgr blog: On retweets, replies, quotes &amp; favorites: A guide for researchers. https://t.co/SjfIuLu…\",true,false\r\n",
      "\"2016-11-03T13:45:17Z\",\"794234002496487424\",\"SocialFeedMgr\",124,27,6,0,,\"http://twitter.com/SocialFeedMgr/status/794234002496487424\",\"RT @ianmilligan1: Used @SocialFeedMgr to collect almost 80,000 #CdnPoli tweets this morning. Great, intuitive UI. https://t.co/BuS3S7f6kf #…\",true,false\r\n",
      "\"2016-11-02T15:24:04Z\",\"793896478037114880\",\"SocialFeedMgr\",124,27,8,4,,\"http://twitter.com/SocialFeedMgr/status/793896478037114880\",\"Software doesn't live forever. How to get collections OUT of Social Feed Manager, a new blog post by @justin_littman https://t.co/CagQvSF7pJ\",false,false\r\n"
     ]
    }
   ],
   "source": [
    "!head -n5 tweets.json | jq -r '[(.created_at | strptime(\"%A %B %d %T %z %Y\") | todate), .id_str, .user.screen_name, .user.followers_count, .user.friends_count, .retweet_count, .favorite_count, .in_reply_to_screen_name, \"http://twitter.com/\" + .user.screen_name + \"/status/\" + .id_str, (.text | gsub(\"\\n\";\" \")), has(\"retweeted_status\"), has(\"quoted_status\")] | @csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Header row\n",
    "The header row should be written to the output file with `>` before appending the CSV with `>>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"created_at\",\"twitter_id\",\"screen_name\",\"followers_count\",\"friends_count\",\"retweet_count\",\"favorite_count\",\"in_reply_to_screen_name\",\"twitter_url\",\"text\",\"is_retweet\",\"is_quote\"\r\n"
     ]
    }
   ],
   "source": [
    "!echo \"[]\" | jq -r '[\"created_at\",\"twitter_id\",\"screen_name\",\"followers_count\",\"friends_count\",\"retweet_count\",\"favorite_count\",\"in_reply_to_screen_name\",\"twitter_url\",\"text\",\"is_retweet\",\"is_quote\"] | @csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting files\n",
    "Excel can load CSV files with over a million rows. Howver, for practical purposes a much smaller number is recommended.\n",
    "\n",
    "The following uses the split command to split the CSV output into multiple files. Note that the flags accepted may be different in your environment.\n",
    "\n",
    "```\n",
    "cat tweets.json | jq -r '[.id_str, (.text | gsub(\"\\n\";\" \"))] | @csv' | split --lines=5 -d --additional-suffix=.csv - tweets\n",
    "ls *.csv\n",
    "tweets00.csv  tweets01.csv  tweets02.csv  tweets03.csv  tweets04.csv\n",
    "tweets05.csv  tweets06.csv  tweets07.csv  tweets08.csv  tweets09.csv\n",
    "```\n",
    "\n",
    "`--lines=5` sets the number of lines to include in each file.\n",
    "\n",
    "`--additional-suffix=.csv` set the file extension.\n",
    "\n",
    "`tweets` is the base name for each file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;39m798895564335280100\u001b[0m\r\n",
      "\u001b[0;39m797074713612877800\u001b[0m\r\n",
      "\u001b[0;39m797064988116611100\u001b[0m\r\n",
      "\u001b[0;39m794234002496487400\u001b[0m\r\n",
      "\u001b[0;39m793896478037114900\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!head -n5 tweets.json | jq -c '.id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
